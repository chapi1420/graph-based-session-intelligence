{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea5a04a",
   "metadata": {},
   "source": [
    "\n",
    "## graph based session intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bb844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/nahomnadew/.cache/kagglehub/datasets/retailrocket/ecommerce-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"retailrocket/ecommerce-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8665a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial parameters\n",
    "\n",
    "DATA_PATH = \"data/kaggle/events.csv\"  \n",
    "SAMPLE_MAX_SESSIONS = 200000  \n",
    "MIN_SESSION_LENGTH = 2  \n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_AUTH = (\"neo4j\", \"nahi1420\")  \n",
    "BATCH_SIZE = 5000  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be81e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 2.3.3\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"pandas\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1fcf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading, this may take a while for the full RetailRocket dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8259/3092328460.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(DATA_PATH, parse_dates=['timestamp'], low_memory=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 2756101\n",
      "Columns: ['timestamp', 'visitorid', 'event', 'itemid', 'transactionid']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid\n",
       "0  1433221332117     257597  view  355908            NaN\n",
       "1  1433224214164     992329  view  248676            NaN\n",
       "2  1433221999827     111016  view  318965            NaN\n",
       "3  1433221955914     483717  view  253185            NaN\n",
       "4  1433221337106     951259  view  367447            NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (may be large)\n",
    "assert os.path.exists(DATA_PATH), f\"Data file not found: {DATA_PATH}\"\n",
    "print(\"Loading, this may take a while for the full RetailRocket dataset...\")\n",
    "\n",
    "# The RetailRocket 'events.csv' has columns similar to: sessionId, itemId, eventType, timestamp\n",
    "usecols = None  \n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['timestamp'], low_memory=False)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e887c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns mapping: {'visitorid': 'session_id', 'event': 'event_type', 'timestamp': 'timestamp'}\n",
      "After filtering short sessions: 406020 unique sessions, 1754541 rows\n"
     ]
    }
   ],
   "source": [
    "# Corrected RetailRocket column mapping\n",
    "cols = [c.lower() for c in df.columns]\n",
    "colmap = {}\n",
    "if 'visitorid' in cols:\n",
    "    colmap[[c for c in df.columns if c.lower()=='visitorid'][0]] = 'session_id'\n",
    "if 'itemid' in cols:\n",
    "    colmap[[c for c in df.columns if c.lower()=='itemid'][0]] = 'event_id'\n",
    "if 'event' in cols:\n",
    "    colmap[[c for c in df.columns if c.lower()=='event'][0]] = 'event_type'\n",
    "if 'timestamp' in cols:\n",
    "    colmap[[c for c in df.columns if c.lower()=='timestamp'][0]] = 'timestamp'\n",
    "\n",
    "df = df.rename(columns=colmap)\n",
    "print('Renamed columns mapping:', colmap)\n",
    "\n",
    "assert 'session_id' in df.columns and 'event_id' in df.columns and 'timestamp' in df.columns\n",
    "\n",
    "# Add step_index per session (order by timestamp)\n",
    "df = df.sort_values(['session_id','timestamp'])\n",
    "df['step_index'] = df.groupby('session_id').cumcount() + 1\n",
    "\n",
    "# Filter out sessions that are too short\n",
    "session_lengths = df.groupby('session_id').size()\n",
    "valid_sessions = session_lengths[session_lengths >= MIN_SESSION_LENGTH].index\n",
    "df = df[df['session_id'].isin(valid_sessions)].copy()\n",
    "print(\"After filtering short sessions:\", df['session_id'].nunique(), \"unique sessions,\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c608219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled sessions: 200000 rows: 869349\n"
     ]
    }
   ],
   "source": [
    "# pick the first N sessions (keeps temporal order inside sessions)\n",
    "if SAMPLE_MAX_SESSIONS is not None:\n",
    "    unique_sess = df['session_id'].drop_duplicates().iloc[:SAMPLE_MAX_SESSIONS]\n",
    "    df = df[df['session_id'].isin(unique_sess)].copy()\n",
    "    print(\"Sampled sessions:\", df['session_id'].nunique(), \"rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe88d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample to data/sampled_sessions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save a sampled CSV for quick checks \n",
    "sample_out = \"data/sampled_sessions.csv\"\n",
    "df.to_csv(sample_out, index=False)\n",
    "print(\"Saved sample to\", sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd87aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
